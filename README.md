# Eye on the Benchmarks

<img src="./src/renderer/assets/icon.png" alt="logo" width="640"/>

Eye on the Benchmarks makes it easy to test and compare AI models.

## Models and Responses

You run one or more prompts at a time and get responses from one or more models at a time. The app makes API calls behind the scenes to these model providers:

| <img src="src/renderer/assets/openai.png" alt="OpenAI" width="20"/> OpenAI | <img src="src/renderer/assets/anthropic.png" alt="Anthropic" width="20"/> Anthropic | <img src="src/renderer/assets/google.png" alt="Google" width="20"/> Google |
|---|---|---|
| GPT 4o | Claude 4 Opus | Gemini 2.5 Pro |
| GPT 4o mini | Claude 4 Sonnet | Gemini 2.5 Flash |
| GPT 4.1 | Claude 3.7 Sonnet | |
| GPT 4.1 mini | Claude 3.5 Haiku | |
| o3 | | |
| o4-mini | | |

Eye on the Benchmarks saves the cost, latency, and resources accessed by the model APIs for the prompts you submit. The goal is to have full transparency and auditability into exactly what models saw and used along the way to their response.

## Context and Features

### Web Search

You can enable/disable web search, which the models use to look for relevant context online before answering questions.

### File Upload

You can directly choose which PDFs the models will use as context to answer questions.

## Installation

### MacOS

Download the installer [here](https://github.com/mcembalest/eyeonthebenchmarks/releases)

### Windows

Coming soon!
